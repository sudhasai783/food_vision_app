# -*- coding: utf-8 -*-
"""predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aRpQe4mqULgHooFfpwlZZw_dG8ogxYkf
"""

# src/predictor.py
import torch
import numpy as np
import torch.nn.functional as F

def predict_topk(model, input_tensor, k=5):
    """
    input_tensor: shape (1,3,H,W) on CPU or GPU depending on model device
    returns list of (class_index:int, probability:float)
    """
    device = next(model.parameters()).device
    input_tensor = input_tensor.to(device)
    model.eval()
    with torch.inference_mode():
        logits = model(input_tensor)
        probs = F.softmax(logits, dim=1).cpu().numpy()[0]
    topk_idx = np.argsort(probs)[-k:][::-1]
    return [(int(i), float(probs[i])) for i in topk_idx]